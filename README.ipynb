{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sccomp_glm_data_frame_counts import sccomp_glm_data_frame_counts\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>type</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>count</th>\n",
       "      <th>cell_group</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10x_6K</td>\n",
       "      <td>benign</td>\n",
       "      <td>b_cell_macrophage_precursor_or_follicular_LTB_...</td>\n",
       "      <td>42</td>\n",
       "      <td>BM</td>\n",
       "      <td>0.008350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10x_6K</td>\n",
       "      <td>benign</td>\n",
       "      <td>B_cell:immature</td>\n",
       "      <td>361</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.071769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10x_6K</td>\n",
       "      <td>benign</td>\n",
       "      <td>B_cell:immature_IGLC3_IGLC2</td>\n",
       "      <td>57</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.011332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10x_6K</td>\n",
       "      <td>benign</td>\n",
       "      <td>B_cell:Memory_ITM2C_IGHA1_MZB1_JCHAIN</td>\n",
       "      <td>40</td>\n",
       "      <td>B3</td>\n",
       "      <td>0.007952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10x_6K</td>\n",
       "      <td>benign</td>\n",
       "      <td>Dendritic_CD11_CD1_high_mito</td>\n",
       "      <td>75</td>\n",
       "      <td>Dm</td>\n",
       "      <td>0.014911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>SRR7244582</td>\n",
       "      <td>benign</td>\n",
       "      <td>T_cell:CD8+_GZMK_DUSP2_LYAR_CCL5</td>\n",
       "      <td>197</td>\n",
       "      <td>CD8 2</td>\n",
       "      <td>0.060727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>SRR7244582</td>\n",
       "      <td>benign</td>\n",
       "      <td>T_cell:CD8+_non_activated</td>\n",
       "      <td>320</td>\n",
       "      <td>CD8 3</td>\n",
       "      <td>0.098644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>SRR7244582</td>\n",
       "      <td>benign</td>\n",
       "      <td>T_cell:CD8+_PPBP_SAT1</td>\n",
       "      <td>39</td>\n",
       "      <td>CD8 4</td>\n",
       "      <td>0.012022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>SRR7244582</td>\n",
       "      <td>benign</td>\n",
       "      <td>T_cell:CD8+_S100B</td>\n",
       "      <td>88</td>\n",
       "      <td>CD8 5</td>\n",
       "      <td>0.027127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>SRR7244582</td>\n",
       "      <td>benign</td>\n",
       "      <td>T_cell:CD8low_TIMP1_PPBP</td>\n",
       "      <td>107</td>\n",
       "      <td>CD8 6</td>\n",
       "      <td>0.032984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sample    type                                          phenotype  \\\n",
       "0        10x_6K  benign  b_cell_macrophage_precursor_or_follicular_LTB_...   \n",
       "1        10x_6K  benign                                    B_cell:immature   \n",
       "2        10x_6K  benign                        B_cell:immature_IGLC3_IGLC2   \n",
       "3        10x_6K  benign              B_cell:Memory_ITM2C_IGHA1_MZB1_JCHAIN   \n",
       "4        10x_6K  benign                       Dendritic_CD11_CD1_high_mito   \n",
       "..          ...     ...                                                ...   \n",
       "715  SRR7244582  benign                   T_cell:CD8+_GZMK_DUSP2_LYAR_CCL5   \n",
       "716  SRR7244582  benign                          T_cell:CD8+_non_activated   \n",
       "717  SRR7244582  benign                              T_cell:CD8+_PPBP_SAT1   \n",
       "718  SRR7244582  benign                                  T_cell:CD8+_S100B   \n",
       "719  SRR7244582  benign                           T_cell:CD8low_TIMP1_PPBP   \n",
       "\n",
       "     count cell_group  proportion  \n",
       "0       42         BM    0.008350  \n",
       "1      361         B1    0.071769  \n",
       "2       57         B2    0.011332  \n",
       "3       40         B3    0.007952  \n",
       "4       75         Dm    0.014911  \n",
       "..     ...        ...         ...  \n",
       "715    197      CD8 2    0.060727  \n",
       "716    320      CD8 3    0.098644  \n",
       "717     39      CD8 4    0.012022  \n",
       "718     88      CD8 5    0.027127  \n",
       "719    107      CD8 6    0.032984  \n",
       "\n",
       "[720 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_obj = pd.read_csv('./data/count_obj.csv')\n",
    "count_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:15:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:15:42 - cmdstanpy - INFO - Chain [2] start processing\n",
      "15:15:42 - cmdstanpy - INFO - Chain [3] start processing\n",
      "15:15:42 - cmdstanpy - INFO - Chain [4] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain [1] method = sample (Default)\n",
      "Chain [1] sample\n",
      "Chain [1] num_samples = 1000 (Default)\n",
      "Chain [1] num_warmup = 1000 (Default)\n",
      "Chain [1] save_warmup = false (Default)\n",
      "Chain [1] thin = 1 (Default)\n",
      "Chain [1] adapt\n",
      "Chain [1] engaged = true (Default)\n",
      "Chain [1] gamma = 0.05 (Default)\n",
      "Chain [1] delta = 0.8 (Default)\n",
      "Chain [1] kappa = 0.75 (Default)\n",
      "Chain [1] t0 = 10 (Default)\n",
      "Chain [1] init_buffer = 75 (Default)\n",
      "Chain [1] term_buffer = 50 (Default)\n",
      "Chain [1] window = 25 (Default)\n",
      "Chain [1] save_metric = false (Default)\n",
      "Chain [1] algorithm = hmc (Default)\n",
      "Chain [1] hmc\n",
      "Chain [1] engine = nuts (Default)\n",
      "Chain [1] nuts\n",
      "Chain [1] max_depth = 10 (Default)\n",
      "Chain [1] metric = diag_e (Default)\n",
      "Chain [1] metric_file =  (Default)\n",
      "Chain [1] stepsize = 1 (Default)\n",
      "Chain [1] stepsize_jitter = 0 (Default)\n",
      "Chain [1] num_chains = 1 (Default)\n",
      "Chain [1] id = 1 (Default)\n",
      "Chain [1] data\n",
      "Chain [1] file = /tmp/tmp6da3fm_o/839vbvu3.json\n",
      "Chain [1] init = 2 (Default)\n",
      "Chain [1] random\n",
      "Chain [1] seed = 85412\n",
      "Chain [1] output\n",
      "Chain [1] file = /tmp/tmp6da3fm_o/glm_multi_beta_binomialit6e71jr/glm_multi_beta_binomial-20241120151542_1.csv\n",
      "Chain [1] diagnostic_file =  (Default)\n",
      "Chain [1] refresh = 100 (Default)\n",
      "Chain [1] sig_figs = -1 (Default)\n",
      "Chain [1] profile_file = profile.csv (Default)\n",
      "Chain [1] save_cmdstan_config = false (Default)\n",
      "Chain [1] num_threads = 1 (Default)\n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] Gradient evaluation took 0.000347 seconds\n",
      "Chain [1] 1000 transitions using 10 leapfrog steps per transition would take 3.47 seconds.\n",
      "Chain [1] Adjust your expectations accordingly!\n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain [1] Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Chain [1] Exception: Exception: beta_binomial_lpmf: First prior sample size parameter[1] is 0, but must be positive finite! (in 'glm_multi_beta_binomial.stan', line 214, column 16 to line 219, column 19) (in 'glm_multi_beta_binomial.stan', line 653, column 3 to line 683, column 8)\n",
      "Chain [1] If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "Chain [1] but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "Chain [1] \n",
      "Chain [2] method = sample (Default)\n",
      "Chain [2] sample\n",
      "Chain [2] num_samples = 1000 (Default)\n",
      "Chain [2] num_warmup = 1000 (Default)\n",
      "Chain [2] save_warmup = false (Default)\n",
      "Chain [2] thin = 1 (Default)\n",
      "Chain [2] adapt\n",
      "Chain [2] engaged = true (Default)\n",
      "Chain [2] gamma = 0.05 (Default)\n",
      "Chain [2] delta = 0.8 (Default)\n",
      "Chain [2] kappa = 0.75 (Default)\n",
      "Chain [2] t0 = 10 (Default)\n",
      "Chain [2] init_buffer = 75 (Default)\n",
      "Chain [2] term_buffer = 50 (Default)\n",
      "Chain [2] window = 25 (Default)\n",
      "Chain [2] save_metric = false (Default)\n",
      "Chain [2] algorithm = hmc (Default)\n",
      "Chain [2] hmc\n",
      "Chain [2] engine = nuts (Default)\n",
      "Chain [2] nuts\n",
      "Chain [2] max_depth = 10 (Default)\n",
      "Chain [2] metric = diag_e (Default)\n",
      "Chain [2] metric_file =  (Default)\n",
      "Chain [2] stepsize = 1 (Default)\n",
      "Chain [2] stepsize_jitter = 0 (Default)\n",
      "Chain [2] num_chains = 1 (Default)\n",
      "Chain [2] id = 2\n",
      "Chain [2] data\n",
      "Chain [2] file = /tmp/tmp6da3fm_o/839vbvu3.json\n",
      "Chain [2] init = 2 (Default)\n",
      "Chain [2] random\n",
      "Chain [2] seed = 85412\n",
      "Chain [2] output\n",
      "Chain [2] file = /tmp/tmp6da3fm_o/glm_multi_beta_binomialit6e71jr/glm_multi_beta_binomial-20241120151542_2.csv\n",
      "Chain [2] diagnostic_file =  (Default)\n",
      "Chain [2] refresh = 100 (Default)\n",
      "Chain [2] sig_figs = -1 (Default)\n",
      "Chain [2] profile_file = profile.csv (Default)\n",
      "Chain [2] save_cmdstan_config = false (Default)\n",
      "Chain [2] num_threads = 1 (Default)\n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] Gradient evaluation took 0.000336 seconds\n",
      "Chain [2] 1000 transitions using 10 leapfrog steps per transition would take 3.36 seconds.\n",
      "Chain [2] Adjust your expectations accordingly!\n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain [2] Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Chain [2] Exception: Exception: beta_binomial_lpmf: Second prior sample size parameter[17] is 0, but must be positive finite! (in 'glm_multi_beta_binomial.stan', line 214, column 16 to line 219, column 19) (in 'glm_multi_beta_binomial.stan', line 653, column 3 to line 683, column 8)\n",
      "Chain [2] If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "Chain [2] but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "Chain [2] \n",
      "Chain [3] method = sample (Default)\n",
      "Chain [3] sample\n",
      "Chain [3] num_samples = 1000 (Default)\n",
      "Chain [3] num_warmup = 1000 (Default)\n",
      "Chain [3] save_warmup = false (Default)\n",
      "Chain [3] thin = 1 (Default)\n",
      "Chain [3] adapt\n",
      "Chain [3] engaged = true (Default)\n",
      "Chain [3] gamma = 0.05 (Default)\n",
      "Chain [3] delta = 0.8 (Default)\n",
      "Chain [3] kappa = 0.75 (Default)\n",
      "Chain [3] t0 = 10 (Default)\n",
      "Chain [3] init_buffer = 75 (Default)\n",
      "Chain [3] term_buffer = 50 (Default)\n",
      "Chain [3] window = 25 (Default)\n",
      "Chain [3] save_metric = false (Default)\n",
      "Chain [3] algorithm = hmc (Default)\n",
      "Chain [3] hmc\n",
      "Chain [3] engine = nuts (Default)\n",
      "Chain [3] nuts\n",
      "Chain [3] max_depth = 10 (Default)\n",
      "Chain [3] metric = diag_e (Default)\n",
      "Chain [3] metric_file =  (Default)\n",
      "Chain [3] stepsize = 1 (Default)\n",
      "Chain [3] stepsize_jitter = 0 (Default)\n",
      "Chain [3] num_chains = 1 (Default)\n",
      "Chain [3] id = 3\n",
      "Chain [3] data\n",
      "Chain [3] file = /tmp/tmp6da3fm_o/839vbvu3.json\n",
      "Chain [3] init = 2 (Default)\n",
      "Chain [3] random\n",
      "Chain [3] seed = 85412\n",
      "Chain [3] output\n",
      "Chain [3] file = /tmp/tmp6da3fm_o/glm_multi_beta_binomialit6e71jr/glm_multi_beta_binomial-20241120151542_3.csv\n",
      "Chain [3] diagnostic_file =  (Default)\n",
      "Chain [3] refresh = 100 (Default)\n",
      "Chain [3] sig_figs = -1 (Default)\n",
      "Chain [3] profile_file = profile.csv (Default)\n",
      "Chain [3] save_cmdstan_config = false (Default)\n",
      "Chain [3] num_threads = 1 (Default)\n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] Gradient evaluation took 0.000341 seconds\n",
      "Chain [3] 1000 transitions using 10 leapfrog steps per transition would take 3.41 seconds.\n",
      "Chain [3] Adjust your expectations accordingly!\n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain [4] method = sample (Default)\n",
      "Chain [4] sample\n",
      "Chain [4] num_samples = 1000 (Default)\n",
      "Chain [4] num_warmup = 1000 (Default)\n",
      "Chain [4] save_warmup = false (Default)\n",
      "Chain [4] thin = 1 (Default)\n",
      "Chain [4] adapt\n",
      "Chain [4] engaged = true (Default)\n",
      "Chain [4] gamma = 0.05 (Default)\n",
      "Chain [4] delta = 0.8 (Default)\n",
      "Chain [4] kappa = 0.75 (Default)\n",
      "Chain [4] t0 = 10 (Default)\n",
      "Chain [4] init_buffer = 75 (Default)\n",
      "Chain [4] term_buffer = 50 (Default)\n",
      "Chain [4] window = 25 (Default)\n",
      "Chain [4] save_metric = false (Default)\n",
      "Chain [4] algorithm = hmc (Default)\n",
      "Chain [4] hmc\n",
      "Chain [4] engine = nuts (Default)\n",
      "Chain [4] nuts\n",
      "Chain [4] max_depth = 10 (Default)\n",
      "Chain [4] metric = diag_e (Default)\n",
      "Chain [4] metric_file =  (Default)\n",
      "Chain [4] stepsize = 1 (Default)\n",
      "Chain [4] stepsize_jitter = 0 (Default)\n",
      "Chain [4] num_chains = 1 (Default)\n",
      "Chain [4] id = 4\n",
      "Chain [4] data\n",
      "Chain [4] file = /tmp/tmp6da3fm_o/839vbvu3.json\n",
      "Chain [4] init = 2 (Default)\n",
      "Chain [4] random\n",
      "Chain [4] seed = 85412\n",
      "Chain [4] output\n",
      "Chain [4] file = /tmp/tmp6da3fm_o/glm_multi_beta_binomialit6e71jr/glm_multi_beta_binomial-20241120151542_4.csv\n",
      "Chain [4] diagnostic_file =  (Default)\n",
      "Chain [4] refresh = 100 (Default)\n",
      "Chain [4] sig_figs = -1 (Default)\n",
      "Chain [4] profile_file = profile.csv (Default)\n",
      "Chain [4] save_cmdstan_config = false (Default)\n",
      "Chain [4] num_threads = 1 (Default)\n",
      "Chain [4] \n",
      "Chain [3] Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Chain [3] Exception: Exception: beta_binomial_lpmf: First prior sample size parameter[1] is 0, but must be positive finite! (in 'glm_multi_beta_binomial.stan', line 214, column 16 to line 219, column 19) (in 'glm_multi_beta_binomial.stan', line 653, column 3 to line 683, column 8)\n",
      "Chain [3] If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "Chain [3] but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "Chain [3] \n",
      "Chain [4] \n",
      "Chain [4] Gradient evaluation took 0.00035 seconds\n",
      "Chain [4] 1000 transitions using 10 leapfrog steps per transition would take 3.5 seconds.\n",
      "Chain [4] Adjust your expectations accordingly!\n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain [4] Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Chain [4] Exception: Exception: beta_binomial_lpmf: Second prior sample size parameter[319] is 0, but must be positive finite! (in 'glm_multi_beta_binomial.stan', line 214, column 16 to line 219, column 19) (in 'glm_multi_beta_binomial.stan', line 653, column 3 to line 683, column 8)\n",
      "Chain [4] If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "Chain [4] but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "Chain [4] \n",
      "Chain [3] Iteration:  100 / 2000 [  5%]  (Warmup)\n",
      "Chain [1] Iteration:  100 / 2000 [  5%]  (Warmup)\n",
      "Chain [2] Iteration:  100 / 2000 [  5%]  (Warmup)\n",
      "Chain [4] Iteration:  100 / 2000 [  5%]  (Warmup)\n",
      "Chain [3] Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain [1] Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain [2] Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain [4] Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain [3] Iteration:  300 / 2000 [ 15%]  (Warmup)\n",
      "Chain [2] Iteration:  300 / 2000 [ 15%]  (Warmup)\n",
      "Chain [1] Iteration:  300 / 2000 [ 15%]  (Warmup)\n",
      "Chain [4] Iteration:  300 / 2000 [ 15%]  (Warmup)\n",
      "Chain [3] Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain [2] Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain [1] Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain [4] Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain [3] Iteration:  500 / 2000 [ 25%]  (Warmup)\n",
      "Chain [2] Iteration:  500 / 2000 [ 25%]  (Warmup)\n",
      "Chain [1] Iteration:  500 / 2000 [ 25%]  (Warmup)\n",
      "Chain [3] Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain [4] Iteration:  500 / 2000 [ 25%]  (Warmup)\n",
      "Chain [2] Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain [1] Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain [3] Iteration:  700 / 2000 [ 35%]  (Warmup)\n",
      "Chain [2] Iteration:  700 / 2000 [ 35%]  (Warmup)\n",
      "Chain [4] Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain [1] Iteration:  700 / 2000 [ 35%]  (Warmup)\n",
      "Chain [3] Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain [2] Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain [4] Iteration:  700 / 2000 [ 35%]  (Warmup)\n",
      "Chain [1] Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain [3] Iteration:  900 / 2000 [ 45%]  (Warmup)\n",
      "Chain [2] Iteration:  900 / 2000 [ 45%]  (Warmup)\n",
      "Chain [4] Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain [1] Iteration:  900 / 2000 [ 45%]  (Warmup)\n",
      "Chain [2] Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain [2] Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain [3] Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain [3] Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain [4] Iteration:  900 / 2000 [ 45%]  (Warmup)\n",
      "Chain [1] Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain [1] Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain [2] Iteration: 1100 / 2000 [ 55%]  (Sampling)\n",
      "Chain [3] Iteration: 1100 / 2000 [ 55%]  (Sampling)\n",
      "Chain [4] Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain [4] Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain [1] Iteration: 1100 / 2000 [ 55%]  (Sampling)\n",
      "Chain [3] Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain [2] Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain [4] Iteration: 1100 / 2000 [ 55%]  (Sampling)\n",
      "Chain [1] Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain [3] Iteration: 1300 / 2000 [ 65%]  (Sampling)\n",
      "Chain [2] Iteration: 1300 / 2000 [ 65%]  (Sampling)\n",
      "Chain [4] Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain [1] Iteration: 1300 / 2000 [ 65%]  (Sampling)\n",
      "Chain [3] Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain [2] Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain [4] Iteration: 1300 / 2000 [ 65%]  (Sampling)\n",
      "Chain [1] Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain [3] Iteration: 1500 / 2000 [ 75%]  (Sampling)\n",
      "Chain [2] Iteration: 1500 / 2000 [ 75%]  (Sampling)\n",
      "Chain [4] Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain [1] Iteration: 1500 / 2000 [ 75%]  (Sampling)\n",
      "Chain [3] Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain [2] Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain [4] Iteration: 1500 / 2000 [ 75%]  (Sampling)\n",
      "Chain [3] Iteration: 1700 / 2000 [ 85%]  (Sampling)\n",
      "Chain [1] Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain [2] Iteration: 1700 / 2000 [ 85%]  (Sampling)\n",
      "Chain [4] Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain [3] Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain [1] Iteration: 1700 / 2000 [ 85%]  (Sampling)\n",
      "Chain [2] Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain [4] Iteration: 1700 / 2000 [ 85%]  (Sampling)\n",
      "Chain [3] Iteration: 1900 / 2000 [ 95%]  (Sampling)\n",
      "Chain [1] Iteration: 1800 / 2000 [ 90%]  (Sampling)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:15:48 - cmdstanpy - INFO - Chain [3] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain [2] Iteration: 1900 / 2000 [ 95%]  (Sampling)\n",
      "Chain [4] Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain [3] Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain [3] \n",
      "Chain [3] Elapsed Time: 3.217 seconds (Warm-up)\n",
      "Chain [3] 2.809 seconds (Sampling)\n",
      "Chain [3] 6.026 seconds (Total)\n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [1] Iteration: 1900 / 2000 [ 95%]  (Sampling)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:15:48 - cmdstanpy - INFO - Chain [2] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain [2] Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain [2] \n",
      "Chain [2] Elapsed Time: 3.211 seconds (Warm-up)\n",
      "Chain [2] 2.998 seconds (Sampling)\n",
      "Chain [2] 6.209 seconds (Total)\n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [4] Iteration: 1900 / 2000 [ 95%]  (Sampling)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:15:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:15:48 - cmdstanpy - INFO - Chain [4] done processing\n",
      "15:15:48 - cmdstanpy - WARNING - Non-fatal error during sampling:\n",
      "Exception: Exception: beta_binomial_lpmf: First prior sample size parameter[1] is 0, but must be positive finite! (in 'glm_multi_beta_binomial.stan', line 214, column 16 to line 219, column 19) (in 'glm_multi_beta_binomial.stan', line 653, column 3 to line 683, column 8)\n",
      "Exception: Exception: beta_binomial_lpmf: Second prior sample size parameter[17] is 0, but must be positive finite! (in 'glm_multi_beta_binomial.stan', line 214, column 16 to line 219, column 19) (in 'glm_multi_beta_binomial.stan', line 653, column 3 to line 683, column 8)\n",
      "Exception: Exception: beta_binomial_lpmf: First prior sample size parameter[1] is 0, but must be positive finite! (in 'glm_multi_beta_binomial.stan', line 214, column 16 to line 219, column 19) (in 'glm_multi_beta_binomial.stan', line 653, column 3 to line 683, column 8)\n",
      "Exception: Exception: beta_binomial_lpmf: Second prior sample size parameter[319] is 0, but must be positive finite! (in 'glm_multi_beta_binomial.stan', line 214, column 16 to line 219, column 19) (in 'glm_multi_beta_binomial.stan', line 653, column 3 to line 683, column 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain [1] Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain [1] \n",
      "Chain [1] Elapsed Time: 3.387 seconds (Warm-up)\n",
      "Chain [1] 3.036 seconds (Sampling)\n",
      "Chain [1] 6.423 seconds (Total)\n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [4] Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain [4] \n",
      "Chain [4] Elapsed Time: 3.559 seconds (Warm-up)\n",
      "Chain [4] 3.009 seconds (Sampling)\n",
      "Chain [4] 6.568 seconds (Total)\n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n"
     ]
    }
   ],
   "source": [
    "res = sccomp_glm_data_frame_counts(\n",
    "    data = count_obj,\n",
    "    formula_composition = '~ 0 + type', \n",
    "    sample = 'sample',\n",
    "    cell_group = 'cell_group',\n",
    "    count = 'count'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit': CmdStanMCMC: model=glm_multi_beta_binomial chains=4['method=sample', 'algorithm=hmc', 'adapt', 'engaged=1']\n",
       "  csv_files:\n",
       " \t/tmp/tmp6da3fm_o/glm_multi_beta_binomialit6e71jr/glm_multi_beta_binomial-20241120151542_1.csv\n",
       " \t/tmp/tmp6da3fm_o/glm_multi_beta_binomialit6e71jr/glm_multi_beta_binomial-20241120151542_2.csv\n",
       " \t/tmp/tmp6da3fm_o/glm_multi_beta_binomialit6e71jr/glm_multi_beta_binomial-20241120151542_3.csv\n",
       " \t/tmp/tmp6da3fm_o/glm_multi_beta_binomialit6e71jr/glm_multi_beta_binomial-20241120151542_4.csv\n",
       "  output_files:\n",
       " \t/tmp/tmp6da3fm_o/glm_multi_beta_binomialit6e71jr/glm_multi_beta_binomial-20241120151542_0-stdout.txt\n",
       " \t/tmp/tmp6da3fm_o/glm_multi_beta_binomialit6e71jr/glm_multi_beta_binomial-20241120151542_1-stdout.txt\n",
       " \t/tmp/tmp6da3fm_o/glm_multi_beta_binomialit6e71jr/glm_multi_beta_binomial-20241120151542_2-stdout.txt\n",
       " \t/tmp/tmp6da3fm_o/glm_multi_beta_binomialit6e71jr/glm_multi_beta_binomial-20241120151542_3-stdout.txt,\n",
       " 'model_input': {'N': 20,\n",
       "  'M': 36,\n",
       "  'exposure': array([ 5030,  8082,  2511,  6161,  6877,  2864,  3199,   601,  4784,\n",
       "          7646,  8734,  3495,  2787,  5446, 25804,  2304,  2570,  2910,\n",
       "         10521,  3244]),\n",
       "  'is_proportion': False,\n",
       "  'y': cell_group     B1   B2   B3   BM  CD4 1  CD4 2  CD4 3  CD4 4  CD4 5  CD8 1  \\\n",
       "  sample                                                                       \n",
       "  10x_6K        361   57   40   42    129    178    701      3    147    431   \n",
       "  10x_8K        537  426   79   87    191    310    862     11    232    561   \n",
       "  GSE115189     136   97   21   21     53     72    340      5     50    191   \n",
       "  SCP345_580    266  209   71   20    201    374    748     11    214    609   \n",
       "  SCP345_860    375  292   94   51    178    352    560     12    228    707   \n",
       "  SCP424_pbmc1  163  102   27   17     60    103    176      6     42    551   \n",
       "  SCP424_pbmc2  325  307   70   23     66    129    191      1     74    347   \n",
       "  SCP591         17    9    7    2     10     43     77      2     11     45   \n",
       "  SI-GA-E5       71   68   23   14    103    168    217      2     87    347   \n",
       "  SI-GA-E7      550  275   77   52    152    243    214      7     97   1228   \n",
       "  SI-GA-E8      577  332  106   33    308    752    475     23    238   1322   \n",
       "  SI-GA-G6       94   60   59   19    128    359    205      9    195    396   \n",
       "  SI-GA-G7       31   16   15   11     58    175     15      3     68    270   \n",
       "  SI-GA-G8      134   90   83   23    189    361    239     12    184    658   \n",
       "  SI-GA-G9      796  568  280  209    663   1278    575      7    269   3681   \n",
       "  SI-GA-H1       60   39   23    9    104    327     28      3    149    241   \n",
       "  SI-GA-H3       40    9   10    5     66    233     76      6     95    305   \n",
       "  SI-GA-H4       58   20    6    8     94    288     43      6    142    377   \n",
       "  SRR11038995   473  257  155   37    259    515    170     12    402   1712   \n",
       "  SRR7244582    178  134   43   22    121    250     86      3    150    506   \n",
       "  \n",
       "  cell_group    ...    M7   M8    M9  NK1  NK2  NK3   NKM  TM1  TM2  TM3  \n",
       "  sample        ...                                                       \n",
       "  10x_6K        ...   233   29   226   86   65  117   128  123   19   25  \n",
       "  10x_8K        ...   416   28   251  156   78  285   233  266   40   63  \n",
       "  GSE115189     ...   125   11   134   39   32   49    84   79   29    0  \n",
       "  SCP345_580    ...   186   13   115  126  103  204   182  145   42   46  \n",
       "  SCP345_860    ...   186   22   195  188   80  405   286  116   47    9  \n",
       "  SCP424_pbmc1  ...    95    9    76   51   33  215   115   25    4   17  \n",
       "  SCP424_pbmc2  ...   139   10    52   81   43  125   104   71   12    0  \n",
       "  SCP591        ...    22    3     9    1    8    3    14   40    2   12  \n",
       "  SI-GA-E5      ...   594   80   332   62   35  114   254  197   52    0  \n",
       "  SI-GA-E7      ...   390   53   342  337  149  417   286  118   26    0  \n",
       "  SI-GA-E8      ...   523   93   225  161  157  400   279  215   41    0  \n",
       "  SI-GA-G6      ...   227   35    93   58   42  121    83   72   18    0  \n",
       "  SI-GA-G7      ...   304   85   113   60   35  107   180  105   27    0  \n",
       "  SI-GA-G8      ...   330   55   145   97   51  147   203  122   23    0  \n",
       "  SI-GA-G9      ...  1863  427  1515  337  532  897  1879  733  335    0  \n",
       "  SI-GA-H1      ...   223   48    63   30   17   55   102   80   11    0  \n",
       "  SI-GA-H3      ...   304   39    99   36   41   74   109   88   25    0  \n",
       "  SI-GA-H4      ...   236   41   101   77   29  132   125   71   14    0  \n",
       "  SRR11038995   ...   342   60   183  553  157  824   498  135   75    0  \n",
       "  SRR7244582    ...   135   15    40   75   40  163   132   74    9    0  \n",
       "  \n",
       "  [20 rows x 36 columns],\n",
       "  'y_proportion': Empty DataFrame\n",
       "  Columns: [B1, B2, B3, BM, CD4 1, CD4 2, CD4 3, CD4 4, CD4 5, CD8 1, CD8 2, CD8 3, CD8 4, CD8 5, CD8 6, Dm, Dp, H1, H2, H3, M1, M2, M3, M4, M5, M6, M7, M8, M9, NK1, NK2, NK3, NKM, TM1, TM2, TM3]\n",
       "  Index: []\n",
       "  \n",
       "  [0 rows x 36 columns],\n",
       "  'X':               type[benign]  type[cancer]\n",
       "  sample                                  \n",
       "  10x_6K                 1.0           0.0\n",
       "  10x_8K                 1.0           0.0\n",
       "  GSE115189              1.0           0.0\n",
       "  SCP345_580             1.0           0.0\n",
       "  SCP345_860             1.0           0.0\n",
       "  SCP424_pbmc1           1.0           0.0\n",
       "  SCP424_pbmc2           1.0           0.0\n",
       "  SCP591                 1.0           0.0\n",
       "  SI-GA-E5               0.0           1.0\n",
       "  SI-GA-E7               0.0           1.0\n",
       "  SI-GA-E8               0.0           1.0\n",
       "  SI-GA-G6               0.0           1.0\n",
       "  SI-GA-G7               0.0           1.0\n",
       "  SI-GA-G8               0.0           1.0\n",
       "  SI-GA-G9               0.0           1.0\n",
       "  SI-GA-H1               0.0           1.0\n",
       "  SI-GA-H3               0.0           1.0\n",
       "  SI-GA-H4               0.0           1.0\n",
       "  SRR11038995            1.0           0.0\n",
       "  SRR7244582             1.0           0.0,\n",
       "  'Xa':               Intercept\n",
       "  sample                 \n",
       "  10x_6K              1.0\n",
       "  10x_8K              1.0\n",
       "  GSE115189           1.0\n",
       "  SCP345_580          1.0\n",
       "  SCP345_860          1.0\n",
       "  SCP424_pbmc1        1.0\n",
       "  SCP424_pbmc2        1.0\n",
       "  SCP591              1.0\n",
       "  SI-GA-E5            1.0\n",
       "  SI-GA-E7            1.0\n",
       "  SI-GA-E8            1.0\n",
       "  SI-GA-G6            1.0\n",
       "  SI-GA-G7            1.0\n",
       "  SI-GA-G8            1.0\n",
       "  SI-GA-G9            1.0\n",
       "  SI-GA-H1            1.0\n",
       "  SI-GA-H3            1.0\n",
       "  SI-GA-H4            1.0\n",
       "  SRR11038995         1.0\n",
       "  SRR7244582          1.0,\n",
       "  'XA':    Intercept\n",
       "  0        1.0,\n",
       "  'C': 2,\n",
       "  'A': 1,\n",
       "  'Ar': 1,\n",
       "  'truncation_ajustment': 1.1,\n",
       "  'is_vb': 1,\n",
       "  'bimodal_mean_variability_association': False,\n",
       "  'use_data': True,\n",
       "  'is_random_effect': 0,\n",
       "  'ncol_X_random_eff': [0, 0],\n",
       "  'n_random_eff': 0,\n",
       "  'n_groups': [0, 0],\n",
       "  'X_random_effect': Empty DataFrame\n",
       "  Columns: []\n",
       "  Index: [10x_6K, 10x_8K, GSE115189, SCP345_580, SCP345_860, SCP424_pbmc1, SCP424_pbmc2, SCP591, SI-GA-E5, SI-GA-E7, SI-GA-E8, SI-GA-G6, SI-GA-G7, SI-GA-G8, SI-GA-G9, SI-GA-H1, SI-GA-H3, SI-GA-H4, SRR11038995, SRR7244582],\n",
       "  'X_random_effect_2': Empty DataFrame\n",
       "  Columns: []\n",
       "  Index: [10x_6K, 10x_8K, GSE115189, SCP345_580, SCP345_860, SCP424_pbmc1, SCP424_pbmc2, SCP591, SI-GA-E5, SI-GA-E7, SI-GA-E8, SI-GA-G6, SI-GA-G7, SI-GA-G8, SI-GA-G9, SI-GA-H1, SI-GA-H3, SI-GA-H4, SRR11038995, SRR7244582],\n",
       "  'group_factor_indexes_for_covariance': Empty DataFrame\n",
       "  Columns: []\n",
       "  Index: [],\n",
       "  'group_factor_indexes_for_covariance_2': Empty DataFrame\n",
       "  Columns: []\n",
       "  Index: [],\n",
       "  'how_many_factors_in_random_design': [0, 0],\n",
       "  'grainsize': 1,\n",
       "  'enable_loo': False,\n",
       "  'is_truncated': 0,\n",
       "  'truncation_up':               BM  B1  B2  B3  Dm  H1  H2  H3  TM1  TM2  ...  CD4 3  TM3  \\\n",
       "  10x_6K        -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  10x_8K        -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  GSE115189     -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SCP345_580    -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SCP345_860    -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SCP424_pbmc1  -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SCP424_pbmc2  -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SCP591        -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-E5      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-E7      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-E8      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-G6      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-G7      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-G8      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-G9      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-H1      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-H3      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-H4      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SRR11038995   -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SRR7244582    -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  \n",
       "                CD4 4  CD4 5  CD8 1  CD8 2  CD8 3  CD8 4  CD8 5  CD8 6  \n",
       "  10x_6K           -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  10x_8K           -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  GSE115189        -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SCP345_580       -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SCP345_860       -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SCP424_pbmc1     -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SCP424_pbmc2     -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SCP591           -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-E5         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-E7         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-E8         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-G6         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-G7         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-G8         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-G9         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-H1         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-H3         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-H4         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SRR11038995      -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SRR7244582       -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  \n",
       "  [20 rows x 36 columns],\n",
       "  'truncation_down':               BM  B1  B2  B3  Dm  H1  H2  H3  TM1  TM2  ...  CD4 3  TM3  \\\n",
       "  10x_6K        -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  10x_8K        -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  GSE115189     -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SCP345_580    -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SCP345_860    -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SCP424_pbmc1  -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SCP424_pbmc2  -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SCP591        -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-E5      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-E7      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-E8      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-G6      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-G7      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-G8      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-G9      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-H1      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-H3      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SI-GA-H4      -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SRR11038995   -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  SRR7244582    -1  -1  -1  -1  -1  -1  -1  -1   -1   -1  ...     -1   -1   \n",
       "  \n",
       "                CD4 4  CD4 5  CD8 1  CD8 2  CD8 3  CD8 4  CD8 5  CD8 6  \n",
       "  10x_6K           -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  10x_8K           -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  GSE115189        -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SCP345_580       -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SCP345_860       -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SCP424_pbmc1     -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SCP424_pbmc2     -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SCP591           -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-E5         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-E7         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-E8         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-G6         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-G7         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-G8         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-G9         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-H1         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-H3         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SI-GA-H4         -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SRR11038995      -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  SRR7244582       -1     -1     -1     -1     -1     -1     -1     -1  \n",
       "  \n",
       "  [20 rows x 36 columns],\n",
       "  'truncation_not_idx': [1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158,\n",
       "   159,\n",
       "   160,\n",
       "   161,\n",
       "   162,\n",
       "   163,\n",
       "   164,\n",
       "   165,\n",
       "   166,\n",
       "   167,\n",
       "   168,\n",
       "   169,\n",
       "   170,\n",
       "   171,\n",
       "   172,\n",
       "   173,\n",
       "   174,\n",
       "   175,\n",
       "   176,\n",
       "   177,\n",
       "   178,\n",
       "   179,\n",
       "   180,\n",
       "   181,\n",
       "   182,\n",
       "   183,\n",
       "   184,\n",
       "   185,\n",
       "   186,\n",
       "   187,\n",
       "   188,\n",
       "   189,\n",
       "   190,\n",
       "   191,\n",
       "   192,\n",
       "   193,\n",
       "   194,\n",
       "   195,\n",
       "   196,\n",
       "   197,\n",
       "   198,\n",
       "   199,\n",
       "   200,\n",
       "   201,\n",
       "   202,\n",
       "   203,\n",
       "   204,\n",
       "   205,\n",
       "   206,\n",
       "   207,\n",
       "   208,\n",
       "   209,\n",
       "   210,\n",
       "   211,\n",
       "   212,\n",
       "   213,\n",
       "   214,\n",
       "   215,\n",
       "   216,\n",
       "   217,\n",
       "   218,\n",
       "   219,\n",
       "   220,\n",
       "   221,\n",
       "   222,\n",
       "   223,\n",
       "   224,\n",
       "   225,\n",
       "   226,\n",
       "   227,\n",
       "   228,\n",
       "   229,\n",
       "   230,\n",
       "   231,\n",
       "   232,\n",
       "   233,\n",
       "   234,\n",
       "   235,\n",
       "   236,\n",
       "   237,\n",
       "   238,\n",
       "   239,\n",
       "   240,\n",
       "   241,\n",
       "   242,\n",
       "   243,\n",
       "   244,\n",
       "   245,\n",
       "   246,\n",
       "   247,\n",
       "   248,\n",
       "   249,\n",
       "   250,\n",
       "   251,\n",
       "   252,\n",
       "   253,\n",
       "   254,\n",
       "   255,\n",
       "   256,\n",
       "   257,\n",
       "   258,\n",
       "   259,\n",
       "   260,\n",
       "   261,\n",
       "   262,\n",
       "   263,\n",
       "   264,\n",
       "   265,\n",
       "   266,\n",
       "   267,\n",
       "   268,\n",
       "   269,\n",
       "   270,\n",
       "   271,\n",
       "   272,\n",
       "   273,\n",
       "   274,\n",
       "   275,\n",
       "   276,\n",
       "   277,\n",
       "   278,\n",
       "   279,\n",
       "   280,\n",
       "   281,\n",
       "   282,\n",
       "   283,\n",
       "   284,\n",
       "   285,\n",
       "   286,\n",
       "   287,\n",
       "   288,\n",
       "   289,\n",
       "   290,\n",
       "   291,\n",
       "   292,\n",
       "   293,\n",
       "   294,\n",
       "   295,\n",
       "   296,\n",
       "   297,\n",
       "   298,\n",
       "   299,\n",
       "   300,\n",
       "   301,\n",
       "   302,\n",
       "   303,\n",
       "   304,\n",
       "   305,\n",
       "   306,\n",
       "   307,\n",
       "   308,\n",
       "   309,\n",
       "   310,\n",
       "   311,\n",
       "   312,\n",
       "   313,\n",
       "   314,\n",
       "   315,\n",
       "   316,\n",
       "   317,\n",
       "   318,\n",
       "   319,\n",
       "   320,\n",
       "   321,\n",
       "   322,\n",
       "   323,\n",
       "   324,\n",
       "   325,\n",
       "   326,\n",
       "   327,\n",
       "   328,\n",
       "   329,\n",
       "   330,\n",
       "   331,\n",
       "   332,\n",
       "   333,\n",
       "   334,\n",
       "   335,\n",
       "   336,\n",
       "   337,\n",
       "   338,\n",
       "   339,\n",
       "   340,\n",
       "   341,\n",
       "   342,\n",
       "   343,\n",
       "   344,\n",
       "   345,\n",
       "   346,\n",
       "   347,\n",
       "   348,\n",
       "   349,\n",
       "   350,\n",
       "   351,\n",
       "   352,\n",
       "   353,\n",
       "   354,\n",
       "   355,\n",
       "   356,\n",
       "   357,\n",
       "   358,\n",
       "   359,\n",
       "   360,\n",
       "   361,\n",
       "   362,\n",
       "   363,\n",
       "   364,\n",
       "   365,\n",
       "   366,\n",
       "   367,\n",
       "   368,\n",
       "   369,\n",
       "   370,\n",
       "   371,\n",
       "   372,\n",
       "   373,\n",
       "   374,\n",
       "   375,\n",
       "   376,\n",
       "   377,\n",
       "   378,\n",
       "   379,\n",
       "   380,\n",
       "   381,\n",
       "   382,\n",
       "   383,\n",
       "   384,\n",
       "   385,\n",
       "   386,\n",
       "   387,\n",
       "   388,\n",
       "   389,\n",
       "   390,\n",
       "   391,\n",
       "   392,\n",
       "   393,\n",
       "   394,\n",
       "   395,\n",
       "   396,\n",
       "   397,\n",
       "   398,\n",
       "   399,\n",
       "   400,\n",
       "   401,\n",
       "   402,\n",
       "   403,\n",
       "   404,\n",
       "   405,\n",
       "   406,\n",
       "   407,\n",
       "   408,\n",
       "   409,\n",
       "   410,\n",
       "   411,\n",
       "   412,\n",
       "   413,\n",
       "   414,\n",
       "   415,\n",
       "   416,\n",
       "   417,\n",
       "   418,\n",
       "   419,\n",
       "   420,\n",
       "   421,\n",
       "   422,\n",
       "   423,\n",
       "   424,\n",
       "   425,\n",
       "   426,\n",
       "   427,\n",
       "   428,\n",
       "   429,\n",
       "   430,\n",
       "   431,\n",
       "   432,\n",
       "   433,\n",
       "   434,\n",
       "   435,\n",
       "   436,\n",
       "   437,\n",
       "   438,\n",
       "   439,\n",
       "   440,\n",
       "   441,\n",
       "   442,\n",
       "   443,\n",
       "   444,\n",
       "   445,\n",
       "   446,\n",
       "   447,\n",
       "   448,\n",
       "   449,\n",
       "   450,\n",
       "   451,\n",
       "   452,\n",
       "   453,\n",
       "   454,\n",
       "   455,\n",
       "   456,\n",
       "   457,\n",
       "   458,\n",
       "   459,\n",
       "   460,\n",
       "   461,\n",
       "   462,\n",
       "   463,\n",
       "   464,\n",
       "   465,\n",
       "   466,\n",
       "   467,\n",
       "   468,\n",
       "   469,\n",
       "   470,\n",
       "   471,\n",
       "   472,\n",
       "   473,\n",
       "   474,\n",
       "   475,\n",
       "   476,\n",
       "   477,\n",
       "   478,\n",
       "   479,\n",
       "   480,\n",
       "   481,\n",
       "   482,\n",
       "   483,\n",
       "   484,\n",
       "   485,\n",
       "   486,\n",
       "   487,\n",
       "   488,\n",
       "   489,\n",
       "   490,\n",
       "   491,\n",
       "   492,\n",
       "   493,\n",
       "   494,\n",
       "   495,\n",
       "   496,\n",
       "   497,\n",
       "   498,\n",
       "   499,\n",
       "   500,\n",
       "   501,\n",
       "   502,\n",
       "   503,\n",
       "   504,\n",
       "   505,\n",
       "   506,\n",
       "   507,\n",
       "   508,\n",
       "   509,\n",
       "   510,\n",
       "   511,\n",
       "   512,\n",
       "   513,\n",
       "   514,\n",
       "   515,\n",
       "   516,\n",
       "   517,\n",
       "   518,\n",
       "   519,\n",
       "   520,\n",
       "   521,\n",
       "   522,\n",
       "   523,\n",
       "   524,\n",
       "   525,\n",
       "   526,\n",
       "   527,\n",
       "   528,\n",
       "   529,\n",
       "   530,\n",
       "   531,\n",
       "   532,\n",
       "   533,\n",
       "   534,\n",
       "   535,\n",
       "   536,\n",
       "   537,\n",
       "   538,\n",
       "   539,\n",
       "   540,\n",
       "   541,\n",
       "   542,\n",
       "   543,\n",
       "   544,\n",
       "   545,\n",
       "   546,\n",
       "   547,\n",
       "   548,\n",
       "   549,\n",
       "   550,\n",
       "   551,\n",
       "   552,\n",
       "   553,\n",
       "   554,\n",
       "   555,\n",
       "   556,\n",
       "   557,\n",
       "   558,\n",
       "   559,\n",
       "   560,\n",
       "   561,\n",
       "   562,\n",
       "   563,\n",
       "   564,\n",
       "   565,\n",
       "   566,\n",
       "   567,\n",
       "   568,\n",
       "   569,\n",
       "   570,\n",
       "   571,\n",
       "   572,\n",
       "   573,\n",
       "   574,\n",
       "   575,\n",
       "   576,\n",
       "   577,\n",
       "   578,\n",
       "   579,\n",
       "   580,\n",
       "   581,\n",
       "   582,\n",
       "   583,\n",
       "   584,\n",
       "   585,\n",
       "   586,\n",
       "   587,\n",
       "   588,\n",
       "   589,\n",
       "   590,\n",
       "   591,\n",
       "   592,\n",
       "   593,\n",
       "   594,\n",
       "   595,\n",
       "   596,\n",
       "   597,\n",
       "   598,\n",
       "   599,\n",
       "   600,\n",
       "   601,\n",
       "   602,\n",
       "   603,\n",
       "   604,\n",
       "   605,\n",
       "   606,\n",
       "   607,\n",
       "   608,\n",
       "   609,\n",
       "   610,\n",
       "   611,\n",
       "   612,\n",
       "   613,\n",
       "   614,\n",
       "   615,\n",
       "   616,\n",
       "   617,\n",
       "   618,\n",
       "   619,\n",
       "   620,\n",
       "   621,\n",
       "   622,\n",
       "   623,\n",
       "   624,\n",
       "   625,\n",
       "   626,\n",
       "   627,\n",
       "   628,\n",
       "   629,\n",
       "   630,\n",
       "   631,\n",
       "   632,\n",
       "   633,\n",
       "   634,\n",
       "   635,\n",
       "   636,\n",
       "   637,\n",
       "   638,\n",
       "   639,\n",
       "   640,\n",
       "   641,\n",
       "   642,\n",
       "   643,\n",
       "   644,\n",
       "   645,\n",
       "   646,\n",
       "   647,\n",
       "   648,\n",
       "   649,\n",
       "   650,\n",
       "   651,\n",
       "   652,\n",
       "   653,\n",
       "   654,\n",
       "   655,\n",
       "   656,\n",
       "   657,\n",
       "   658,\n",
       "   659,\n",
       "   660,\n",
       "   661,\n",
       "   662,\n",
       "   663,\n",
       "   664,\n",
       "   665,\n",
       "   666,\n",
       "   667,\n",
       "   668,\n",
       "   669,\n",
       "   670,\n",
       "   671,\n",
       "   672,\n",
       "   673,\n",
       "   674,\n",
       "   675,\n",
       "   676,\n",
       "   677,\n",
       "   678,\n",
       "   679,\n",
       "   680,\n",
       "   681,\n",
       "   682,\n",
       "   683,\n",
       "   684,\n",
       "   685,\n",
       "   686,\n",
       "   687,\n",
       "   688,\n",
       "   689,\n",
       "   690,\n",
       "   691,\n",
       "   692,\n",
       "   693,\n",
       "   694,\n",
       "   695,\n",
       "   696,\n",
       "   697,\n",
       "   698,\n",
       "   699,\n",
       "   700,\n",
       "   701,\n",
       "   702,\n",
       "   703,\n",
       "   704,\n",
       "   705,\n",
       "   706,\n",
       "   707,\n",
       "   708,\n",
       "   709,\n",
       "   710,\n",
       "   711,\n",
       "   712,\n",
       "   713,\n",
       "   714,\n",
       "   715,\n",
       "   716,\n",
       "   717,\n",
       "   718,\n",
       "   719,\n",
       "   720],\n",
       "  'TNS': 720,\n",
       "  'truncation_not_idx_minimal': array([], shape=(0, 2), dtype=float64),\n",
       "  'TNIM': 0,\n",
       "  'intercept_in_design': False,\n",
       "  'A_intercept_columns': 1,\n",
       "  'B_intercept_columns': 2,\n",
       "  'user_forced_truncation_not_idx': [1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158,\n",
       "   159,\n",
       "   160,\n",
       "   161,\n",
       "   162,\n",
       "   163,\n",
       "   164,\n",
       "   165,\n",
       "   166,\n",
       "   167,\n",
       "   168,\n",
       "   169,\n",
       "   170,\n",
       "   171,\n",
       "   172,\n",
       "   173,\n",
       "   174,\n",
       "   175,\n",
       "   176,\n",
       "   177,\n",
       "   178,\n",
       "   179,\n",
       "   180,\n",
       "   181,\n",
       "   182,\n",
       "   183,\n",
       "   184,\n",
       "   185,\n",
       "   186,\n",
       "   187,\n",
       "   188,\n",
       "   189,\n",
       "   190,\n",
       "   191,\n",
       "   192,\n",
       "   193,\n",
       "   194,\n",
       "   195,\n",
       "   196,\n",
       "   197,\n",
       "   198,\n",
       "   199,\n",
       "   200,\n",
       "   201,\n",
       "   202,\n",
       "   203,\n",
       "   204,\n",
       "   205,\n",
       "   206,\n",
       "   207,\n",
       "   208,\n",
       "   209,\n",
       "   210,\n",
       "   211,\n",
       "   212,\n",
       "   213,\n",
       "   214,\n",
       "   215,\n",
       "   216,\n",
       "   217,\n",
       "   218,\n",
       "   219,\n",
       "   220,\n",
       "   221,\n",
       "   222,\n",
       "   223,\n",
       "   224,\n",
       "   225,\n",
       "   226,\n",
       "   227,\n",
       "   228,\n",
       "   229,\n",
       "   230,\n",
       "   231,\n",
       "   232,\n",
       "   233,\n",
       "   234,\n",
       "   235,\n",
       "   236,\n",
       "   237,\n",
       "   238,\n",
       "   239,\n",
       "   240,\n",
       "   241,\n",
       "   242,\n",
       "   243,\n",
       "   244,\n",
       "   245,\n",
       "   246,\n",
       "   247,\n",
       "   248,\n",
       "   249,\n",
       "   250,\n",
       "   251,\n",
       "   252,\n",
       "   253,\n",
       "   254,\n",
       "   255,\n",
       "   256,\n",
       "   257,\n",
       "   258,\n",
       "   259,\n",
       "   260,\n",
       "   261,\n",
       "   262,\n",
       "   263,\n",
       "   264,\n",
       "   265,\n",
       "   266,\n",
       "   267,\n",
       "   268,\n",
       "   269,\n",
       "   270,\n",
       "   271,\n",
       "   272,\n",
       "   273,\n",
       "   274,\n",
       "   275,\n",
       "   276,\n",
       "   277,\n",
       "   278,\n",
       "   279,\n",
       "   280,\n",
       "   281,\n",
       "   282,\n",
       "   283,\n",
       "   284,\n",
       "   285,\n",
       "   286,\n",
       "   287,\n",
       "   288,\n",
       "   289,\n",
       "   290,\n",
       "   291,\n",
       "   292,\n",
       "   293,\n",
       "   294,\n",
       "   295,\n",
       "   296,\n",
       "   297,\n",
       "   298,\n",
       "   299,\n",
       "   300,\n",
       "   301,\n",
       "   302,\n",
       "   303,\n",
       "   304,\n",
       "   305,\n",
       "   306,\n",
       "   307,\n",
       "   308,\n",
       "   309,\n",
       "   310,\n",
       "   311,\n",
       "   312,\n",
       "   313,\n",
       "   314,\n",
       "   315,\n",
       "   316,\n",
       "   317,\n",
       "   318,\n",
       "   319,\n",
       "   320,\n",
       "   321,\n",
       "   322,\n",
       "   323,\n",
       "   324,\n",
       "   325,\n",
       "   326,\n",
       "   327,\n",
       "   328,\n",
       "   329,\n",
       "   330,\n",
       "   331,\n",
       "   332,\n",
       "   333,\n",
       "   334,\n",
       "   335,\n",
       "   336,\n",
       "   337,\n",
       "   338,\n",
       "   339,\n",
       "   340,\n",
       "   341,\n",
       "   342,\n",
       "   343,\n",
       "   344,\n",
       "   345,\n",
       "   346,\n",
       "   347,\n",
       "   348,\n",
       "   349,\n",
       "   350,\n",
       "   351,\n",
       "   352,\n",
       "   353,\n",
       "   354,\n",
       "   355,\n",
       "   356,\n",
       "   357,\n",
       "   358,\n",
       "   359,\n",
       "   360,\n",
       "   361,\n",
       "   362,\n",
       "   363,\n",
       "   364,\n",
       "   365,\n",
       "   366,\n",
       "   367,\n",
       "   368,\n",
       "   369,\n",
       "   370,\n",
       "   371,\n",
       "   372,\n",
       "   373,\n",
       "   374,\n",
       "   375,\n",
       "   376,\n",
       "   377,\n",
       "   378,\n",
       "   379,\n",
       "   380,\n",
       "   381,\n",
       "   382,\n",
       "   383,\n",
       "   384,\n",
       "   385,\n",
       "   386,\n",
       "   387,\n",
       "   388,\n",
       "   389,\n",
       "   390,\n",
       "   391,\n",
       "   392,\n",
       "   393,\n",
       "   394,\n",
       "   395,\n",
       "   396,\n",
       "   397,\n",
       "   398,\n",
       "   399,\n",
       "   400,\n",
       "   401,\n",
       "   402,\n",
       "   403,\n",
       "   404,\n",
       "   405,\n",
       "   406,\n",
       "   407,\n",
       "   408,\n",
       "   409,\n",
       "   410,\n",
       "   411,\n",
       "   412,\n",
       "   413,\n",
       "   414,\n",
       "   415,\n",
       "   416,\n",
       "   417,\n",
       "   418,\n",
       "   419,\n",
       "   420,\n",
       "   421,\n",
       "   422,\n",
       "   423,\n",
       "   424,\n",
       "   425,\n",
       "   426,\n",
       "   427,\n",
       "   428,\n",
       "   429,\n",
       "   430,\n",
       "   431,\n",
       "   432,\n",
       "   433,\n",
       "   434,\n",
       "   435,\n",
       "   436,\n",
       "   437,\n",
       "   438,\n",
       "   439,\n",
       "   440,\n",
       "   441,\n",
       "   442,\n",
       "   443,\n",
       "   444,\n",
       "   445,\n",
       "   446,\n",
       "   447,\n",
       "   448,\n",
       "   449,\n",
       "   450,\n",
       "   451,\n",
       "   452,\n",
       "   453,\n",
       "   454,\n",
       "   455,\n",
       "   456,\n",
       "   457,\n",
       "   458,\n",
       "   459,\n",
       "   460,\n",
       "   461,\n",
       "   462,\n",
       "   463,\n",
       "   464,\n",
       "   465,\n",
       "   466,\n",
       "   467,\n",
       "   468,\n",
       "   469,\n",
       "   470,\n",
       "   471,\n",
       "   472,\n",
       "   473,\n",
       "   474,\n",
       "   475,\n",
       "   476,\n",
       "   477,\n",
       "   478,\n",
       "   479,\n",
       "   480,\n",
       "   481,\n",
       "   482,\n",
       "   483,\n",
       "   484,\n",
       "   485,\n",
       "   486,\n",
       "   487,\n",
       "   488,\n",
       "   489,\n",
       "   490,\n",
       "   491,\n",
       "   492,\n",
       "   493,\n",
       "   494,\n",
       "   495,\n",
       "   496,\n",
       "   497,\n",
       "   498,\n",
       "   499,\n",
       "   500,\n",
       "   501,\n",
       "   502,\n",
       "   503,\n",
       "   504,\n",
       "   505,\n",
       "   506,\n",
       "   507,\n",
       "   508,\n",
       "   509,\n",
       "   510,\n",
       "   511,\n",
       "   512,\n",
       "   513,\n",
       "   514,\n",
       "   515,\n",
       "   516,\n",
       "   517,\n",
       "   518,\n",
       "   519,\n",
       "   520,\n",
       "   521,\n",
       "   522,\n",
       "   523,\n",
       "   524,\n",
       "   525,\n",
       "   526,\n",
       "   527,\n",
       "   528,\n",
       "   529,\n",
       "   530,\n",
       "   531,\n",
       "   532,\n",
       "   533,\n",
       "   534,\n",
       "   535,\n",
       "   536,\n",
       "   537,\n",
       "   538,\n",
       "   539,\n",
       "   540,\n",
       "   541,\n",
       "   542,\n",
       "   543,\n",
       "   544,\n",
       "   545,\n",
       "   546,\n",
       "   547,\n",
       "   548,\n",
       "   549,\n",
       "   550,\n",
       "   551,\n",
       "   552,\n",
       "   553,\n",
       "   554,\n",
       "   555,\n",
       "   556,\n",
       "   557,\n",
       "   558,\n",
       "   559,\n",
       "   560,\n",
       "   561,\n",
       "   562,\n",
       "   563,\n",
       "   564,\n",
       "   565,\n",
       "   566,\n",
       "   567,\n",
       "   568,\n",
       "   569,\n",
       "   570,\n",
       "   571,\n",
       "   572,\n",
       "   573,\n",
       "   574,\n",
       "   575,\n",
       "   576,\n",
       "   577,\n",
       "   578,\n",
       "   579,\n",
       "   580,\n",
       "   581,\n",
       "   582,\n",
       "   583,\n",
       "   584,\n",
       "   585,\n",
       "   586,\n",
       "   587,\n",
       "   588,\n",
       "   589,\n",
       "   590,\n",
       "   591,\n",
       "   592,\n",
       "   593,\n",
       "   594,\n",
       "   595,\n",
       "   596,\n",
       "   597,\n",
       "   598,\n",
       "   599,\n",
       "   600,\n",
       "   601,\n",
       "   602,\n",
       "   603,\n",
       "   604,\n",
       "   605,\n",
       "   606,\n",
       "   607,\n",
       "   608,\n",
       "   609,\n",
       "   610,\n",
       "   611,\n",
       "   612,\n",
       "   613,\n",
       "   614,\n",
       "   615,\n",
       "   616,\n",
       "   617,\n",
       "   618,\n",
       "   619,\n",
       "   620,\n",
       "   621,\n",
       "   622,\n",
       "   623,\n",
       "   624,\n",
       "   625,\n",
       "   626,\n",
       "   627,\n",
       "   628,\n",
       "   629,\n",
       "   630,\n",
       "   631,\n",
       "   632,\n",
       "   633,\n",
       "   634,\n",
       "   635,\n",
       "   636,\n",
       "   637,\n",
       "   638,\n",
       "   639,\n",
       "   640,\n",
       "   641,\n",
       "   642,\n",
       "   643,\n",
       "   644,\n",
       "   645,\n",
       "   646,\n",
       "   647,\n",
       "   648,\n",
       "   649,\n",
       "   650,\n",
       "   651,\n",
       "   652,\n",
       "   653,\n",
       "   654,\n",
       "   655,\n",
       "   656,\n",
       "   657,\n",
       "   658,\n",
       "   659,\n",
       "   660,\n",
       "   661,\n",
       "   662,\n",
       "   663,\n",
       "   664,\n",
       "   665,\n",
       "   666,\n",
       "   667,\n",
       "   668,\n",
       "   669,\n",
       "   670,\n",
       "   671,\n",
       "   672,\n",
       "   673,\n",
       "   674,\n",
       "   675,\n",
       "   676,\n",
       "   677,\n",
       "   678,\n",
       "   679,\n",
       "   680,\n",
       "   681,\n",
       "   682,\n",
       "   683,\n",
       "   684,\n",
       "   685,\n",
       "   686,\n",
       "   687,\n",
       "   688,\n",
       "   689,\n",
       "   690,\n",
       "   691,\n",
       "   692,\n",
       "   693,\n",
       "   694,\n",
       "   695,\n",
       "   696,\n",
       "   697,\n",
       "   698,\n",
       "   699,\n",
       "   700,\n",
       "   701,\n",
       "   702,\n",
       "   703,\n",
       "   704,\n",
       "   705,\n",
       "   706,\n",
       "   707,\n",
       "   708,\n",
       "   709,\n",
       "   710,\n",
       "   711,\n",
       "   712,\n",
       "   713,\n",
       "   714,\n",
       "   715,\n",
       "   716,\n",
       "   717,\n",
       "   718,\n",
       "   719,\n",
       "   720],\n",
       "  'prior_prec_intercept': [5, 2],\n",
       "  'prior_prec_slope': [0, 0.6],\n",
       "  'prior_prec_sd': [20, 40],\n",
       "  'prior_mean_intercept': [0, 1],\n",
       "  'prior_mean_coefficients': [0, 1],\n",
       "  'exclude_priors': False},\n",
       " 'truncation_df2':          sample    type                                          phenotype  \\\n",
       " 0        10x_6K  benign  b_cell_macrophage_precursor_or_follicular_LTB_...   \n",
       " 1        10x_6K  benign                                    B_cell:immature   \n",
       " 2        10x_6K  benign                        B_cell:immature_IGLC3_IGLC2   \n",
       " 3        10x_6K  benign              B_cell:Memory_ITM2C_IGHA1_MZB1_JCHAIN   \n",
       " 4        10x_6K  benign                       Dendritic_CD11_CD1_high_mito   \n",
       " ..          ...     ...                                                ...   \n",
       " 715  SRR7244582  benign                   T_cell:CD8+_GZMK_DUSP2_LYAR_CCL5   \n",
       " 716  SRR7244582  benign                          T_cell:CD8+_non_activated   \n",
       " 717  SRR7244582  benign                              T_cell:CD8+_PPBP_SAT1   \n",
       " 718  SRR7244582  benign                                  T_cell:CD8+_S100B   \n",
       " 719  SRR7244582  benign                           T_cell:CD8low_TIMP1_PPBP   \n",
       " \n",
       "      count cell_group  proportion  \n",
       " 0       42         BM    0.008350  \n",
       " 1      361         B1    0.071769  \n",
       " 2       57         B2    0.011332  \n",
       " 3       40         B3    0.007952  \n",
       " 4       75         Dm    0.014911  \n",
       " ..     ...        ...         ...  \n",
       " 715    197      CD8 2    0.060727  \n",
       " 716    320      CD8 3    0.098644  \n",
       " 717     39      CD8 4    0.012022  \n",
       " 718     88      CD8 5    0.027127  \n",
       " 719    107      CD8 6    0.032984  \n",
       " \n",
       " [720 rows x 6 columns],\n",
       " 'sample': 'sample',\n",
       " 'cell_group': 'cell_group',\n",
       " 'count': 'count',\n",
       " 'formula_composition': 'count ~ 0 + type',\n",
       " 'formula_variability': 'count ~ 1'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>MCSE</th>\n",
       "      <th>StdDev</th>\n",
       "      <th>5%</th>\n",
       "      <th>50%</th>\n",
       "      <th>95%</th>\n",
       "      <th>N_Eff</th>\n",
       "      <th>N_Eff/s</th>\n",
       "      <th>R_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lp__</th>\n",
       "      <td>-478862.000000</td>\n",
       "      <td>0.201128</td>\n",
       "      <td>7.744450</td>\n",
       "      <td>-478875.000000</td>\n",
       "      <td>-478862.000000</td>\n",
       "      <td>-478850.000000</td>\n",
       "      <td>1482.64</td>\n",
       "      <td>125.096</td>\n",
       "      <td>1.002760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_raw_raw[1,1]</th>\n",
       "      <td>-0.851710</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.089750</td>\n",
       "      <td>-0.995773</td>\n",
       "      <td>-0.853185</td>\n",
       "      <td>-0.700119</td>\n",
       "      <td>4628.97</td>\n",
       "      <td>390.565</td>\n",
       "      <td>0.999658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_raw_raw[1,2]</th>\n",
       "      <td>-0.559476</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.114248</td>\n",
       "      <td>-0.743821</td>\n",
       "      <td>-0.561733</td>\n",
       "      <td>-0.368726</td>\n",
       "      <td>5432.09</td>\n",
       "      <td>458.326</td>\n",
       "      <td>0.999516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_raw_raw[1,3]</th>\n",
       "      <td>0.222124</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.102762</td>\n",
       "      <td>0.049287</td>\n",
       "      <td>0.223507</td>\n",
       "      <td>0.387130</td>\n",
       "      <td>5635.92</td>\n",
       "      <td>475.524</td>\n",
       "      <td>0.999255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_raw_raw[1,4]</th>\n",
       "      <td>0.698659</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.103672</td>\n",
       "      <td>0.532746</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>0.865552</td>\n",
       "      <td>5212.22</td>\n",
       "      <td>439.776</td>\n",
       "      <td>0.999557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[716]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[717]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[718]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[719]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[720]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1731 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Mean      MCSE    StdDev             5%  \\\n",
       "lp__              -478862.000000  0.201128  7.744450 -478875.000000   \n",
       "beta_raw_raw[1,1]      -0.851710  0.001319  0.089750      -0.995773   \n",
       "beta_raw_raw[1,2]      -0.559476  0.001550  0.114248      -0.743821   \n",
       "beta_raw_raw[1,3]       0.222124  0.001369  0.102762       0.049287   \n",
       "beta_raw_raw[1,4]       0.698659  0.001436  0.103672       0.532746   \n",
       "...                          ...       ...       ...            ...   \n",
       "log_lik[716]            0.000000       NaN  0.000000       0.000000   \n",
       "log_lik[717]            0.000000       NaN  0.000000       0.000000   \n",
       "log_lik[718]            0.000000       NaN  0.000000       0.000000   \n",
       "log_lik[719]            0.000000       NaN  0.000000       0.000000   \n",
       "log_lik[720]            0.000000       NaN  0.000000       0.000000   \n",
       "\n",
       "                             50%            95%    N_Eff  N_Eff/s     R_hat  \n",
       "lp__              -478862.000000 -478850.000000  1482.64  125.096  1.002760  \n",
       "beta_raw_raw[1,1]      -0.853185      -0.700119  4628.97  390.565  0.999658  \n",
       "beta_raw_raw[1,2]      -0.561733      -0.368726  5432.09  458.326  0.999516  \n",
       "beta_raw_raw[1,3]       0.223507       0.387130  5635.92  475.524  0.999255  \n",
       "beta_raw_raw[1,4]       0.699115       0.865552  5212.22  439.776  0.999557  \n",
       "...                          ...            ...      ...      ...       ...  \n",
       "log_lik[716]            0.000000       0.000000      NaN      NaN       NaN  \n",
       "log_lik[717]            0.000000       0.000000      NaN      NaN       NaN  \n",
       "log_lik[718]            0.000000       0.000000      NaN      NaN       NaN  \n",
       "log_lik[719]            0.000000       0.000000      NaN      NaN       NaN  \n",
       "log_lik[720]            0.000000       0.000000      NaN      NaN       NaN  \n",
       "\n",
       "[1731 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.get('fit').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chain__</th>\n",
       "      <th>iter__</th>\n",
       "      <th>draw__</th>\n",
       "      <th>variable</th>\n",
       "      <th>C</th>\n",
       "      <th>M</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>beta</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.11395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>beta</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>beta</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.07330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>beta</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.08607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>beta</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.08114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287995</th>\n",
       "      <td>4.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>3996</td>\n",
       "      <td>beta</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>-3.58752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287996</th>\n",
       "      <td>4.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>3997</td>\n",
       "      <td>beta</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>-2.19155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287997</th>\n",
       "      <td>4.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>3998</td>\n",
       "      <td>beta</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>-3.44460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287998</th>\n",
       "      <td>4.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>3999</td>\n",
       "      <td>beta</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>-3.34627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287999</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>beta</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>-3.92117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        chain__  iter__  draw__ variable  C   M    value\n",
       "0           1.0     1.0       1     beta  1   1  1.11395\n",
       "1           1.0     2.0       2     beta  1   1  1.33269\n",
       "2           1.0     3.0       3     beta  1   1  1.07330\n",
       "3           1.0     4.0       4     beta  1   1  1.08607\n",
       "4           1.0     5.0       5     beta  1   1  1.08114\n",
       "...         ...     ...     ...      ... ..  ..      ...\n",
       "287995      4.0   996.0    3996     beta  2  36 -3.58752\n",
       "287996      4.0   997.0    3997     beta  2  36 -2.19155\n",
       "287997      4.0   998.0    3998     beta  2  36 -3.44460\n",
       "287998      4.0   999.0    3999     beta  2  36 -3.34627\n",
       "287999      4.0  1000.0    4000     beta  2  36 -3.92117\n",
       "\n",
       "[288000 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utilities import draws_to_tibble_x_y\n",
    "draws_to_tibble_x_y(res.get('fit'), 'beta', 'C', 'M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is for dev:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res\n",
    "# Retrieve attributes from data\n",
    "cell_group = data.get(\"cell_group\", None)\n",
    "model_input = data.get(\"model_input\", {})\n",
    "fit = data.get(\"fit\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_factor_of_interest = data.get('model_input').get(\"X\").columns.tolist()\n",
    "beta = draws_to_tibble_x_y(fit, \"beta\", \"C\", \"M\")\n",
    "beta = beta.pivot(index = ['chain__', 'iter__', 'draw__', 'variable', 'M'], columns='C', values='value')\n",
    "beta.columns = beta_factor_of_interest\n",
    "beta.reset_index(inplace=True)\n",
    "\n",
    "# Abundance\n",
    "draws = beta.drop(columns=['variable'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts = ['type[cancer] - type[benign]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chain__</th>\n",
       "      <th>iter__</th>\n",
       "      <th>draw__</th>\n",
       "      <th>M</th>\n",
       "      <th>type[benign]</th>\n",
       "      <th>type[cancer]</th>\n",
       "      <th>type[cancer] - type[benign]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.113950</td>\n",
       "      <td>0.568550</td>\n",
       "      <td>-0.545400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.168845</td>\n",
       "      <td>0.456314</td>\n",
       "      <td>0.287469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.565325</td>\n",
       "      <td>-0.448879</td>\n",
       "      <td>0.116446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.958012</td>\n",
       "      <td>-1.432450</td>\n",
       "      <td>-0.474438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.379973</td>\n",
       "      <td>0.571938</td>\n",
       "      <td>0.191965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143995</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>32</td>\n",
       "      <td>0.450490</td>\n",
       "      <td>0.897604</td>\n",
       "      <td>0.447114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143996</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>33</td>\n",
       "      <td>0.692265</td>\n",
       "      <td>0.863377</td>\n",
       "      <td>0.171112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143997</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>34</td>\n",
       "      <td>0.064553</td>\n",
       "      <td>0.485498</td>\n",
       "      <td>0.420945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143998</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>-1.252890</td>\n",
       "      <td>-0.746289</td>\n",
       "      <td>0.506601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143999</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.813960</td>\n",
       "      <td>-3.921170</td>\n",
       "      <td>-3.107210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        chain__  iter__  draw__   M  type[benign]  type[cancer]  \\\n",
       "0           1.0     1.0       1   1      1.113950      0.568550   \n",
       "1           1.0     1.0       1   2      0.168845      0.456314   \n",
       "2           1.0     1.0       1   3     -0.565325     -0.448879   \n",
       "3           1.0     1.0       1   4     -0.958012     -1.432450   \n",
       "4           1.0     1.0       1   5      0.379973      0.571938   \n",
       "...         ...     ...     ...  ..           ...           ...   \n",
       "143995      4.0  1000.0    4000  32      0.450490      0.897604   \n",
       "143996      4.0  1000.0    4000  33      0.692265      0.863377   \n",
       "143997      4.0  1000.0    4000  34      0.064553      0.485498   \n",
       "143998      4.0  1000.0    4000  35     -1.252890     -0.746289   \n",
       "143999      4.0  1000.0    4000  36     -0.813960     -3.921170   \n",
       "\n",
       "        type[cancer] - type[benign]  \n",
       "0                         -0.545400  \n",
       "1                          0.287469  \n",
       "2                          0.116446  \n",
       "3                         -0.474438  \n",
       "4                          0.191965  \n",
       "...                             ...  \n",
       "143995                     0.447114  \n",
       "143996                     0.171112  \n",
       "143997                     0.420945  \n",
       "143998                     0.506601  \n",
       "143999                    -3.107210  \n",
       "\n",
       "[144000 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utilities import mutate_from_expr_list\n",
    "mutate_from_expr_list(x = draws, formula_expr = contrasts )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>C</th>\n",
       "      <th>M</th>\n",
       "      <th>Mean</th>\n",
       "      <th>5%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>N_Eff</th>\n",
       "      <th>R_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.38631</td>\n",
       "      <td>4.81802</td>\n",
       "      <td>5.16575</td>\n",
       "      <td>5.39372</td>\n",
       "      <td>5.62138</td>\n",
       "      <td>5.92607</td>\n",
       "      <td>6719.16</td>\n",
       "      <td>0.999286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.03404</td>\n",
       "      <td>4.50915</td>\n",
       "      <td>4.82649</td>\n",
       "      <td>5.04351</td>\n",
       "      <td>5.24269</td>\n",
       "      <td>5.52481</td>\n",
       "      <td>6301.44</td>\n",
       "      <td>0.999518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.85896</td>\n",
       "      <td>5.25886</td>\n",
       "      <td>5.62377</td>\n",
       "      <td>5.87032</td>\n",
       "      <td>6.09556</td>\n",
       "      <td>6.44078</td>\n",
       "      <td>6193.23</td>\n",
       "      <td>0.999466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6.22735</td>\n",
       "      <td>5.58510</td>\n",
       "      <td>5.96934</td>\n",
       "      <td>6.24014</td>\n",
       "      <td>6.49068</td>\n",
       "      <td>6.84753</td>\n",
       "      <td>6312.61</td>\n",
       "      <td>1.000360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.30527</td>\n",
       "      <td>5.67456</td>\n",
       "      <td>6.05886</td>\n",
       "      <td>6.30803</td>\n",
       "      <td>6.56363</td>\n",
       "      <td>6.90561</td>\n",
       "      <td>5330.25</td>\n",
       "      <td>0.999735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5.13622</td>\n",
       "      <td>4.60722</td>\n",
       "      <td>4.92619</td>\n",
       "      <td>5.14621</td>\n",
       "      <td>5.35742</td>\n",
       "      <td>5.63415</td>\n",
       "      <td>6929.55</td>\n",
       "      <td>0.999514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4.70524</td>\n",
       "      <td>4.13465</td>\n",
       "      <td>4.48862</td>\n",
       "      <td>4.71143</td>\n",
       "      <td>4.93371</td>\n",
       "      <td>5.24208</td>\n",
       "      <td>6227.78</td>\n",
       "      <td>0.999400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5.92780</td>\n",
       "      <td>5.15570</td>\n",
       "      <td>5.61018</td>\n",
       "      <td>5.91999</td>\n",
       "      <td>6.24600</td>\n",
       "      <td>6.71451</td>\n",
       "      <td>4761.11</td>\n",
       "      <td>1.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5.24260</td>\n",
       "      <td>4.71491</td>\n",
       "      <td>5.02770</td>\n",
       "      <td>5.25466</td>\n",
       "      <td>5.46240</td>\n",
       "      <td>5.73385</td>\n",
       "      <td>6326.87</td>\n",
       "      <td>0.999544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5.45833</td>\n",
       "      <td>4.85158</td>\n",
       "      <td>5.21739</td>\n",
       "      <td>5.47406</td>\n",
       "      <td>5.70327</td>\n",
       "      <td>6.03089</td>\n",
       "      <td>5643.33</td>\n",
       "      <td>0.999882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>5.78892</td>\n",
       "      <td>5.17515</td>\n",
       "      <td>5.55274</td>\n",
       "      <td>5.79319</td>\n",
       "      <td>6.03913</td>\n",
       "      <td>6.38503</td>\n",
       "      <td>7027.98</td>\n",
       "      <td>0.999554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4.92534</td>\n",
       "      <td>4.38732</td>\n",
       "      <td>4.71852</td>\n",
       "      <td>4.93312</td>\n",
       "      <td>5.14611</td>\n",
       "      <td>5.43436</td>\n",
       "      <td>5949.61</td>\n",
       "      <td>0.999587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5.80717</td>\n",
       "      <td>5.23944</td>\n",
       "      <td>5.57942</td>\n",
       "      <td>5.81697</td>\n",
       "      <td>6.04676</td>\n",
       "      <td>6.34499</td>\n",
       "      <td>6359.12</td>\n",
       "      <td>0.999285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>4.73283</td>\n",
       "      <td>4.22334</td>\n",
       "      <td>4.53628</td>\n",
       "      <td>4.74700</td>\n",
       "      <td>4.93864</td>\n",
       "      <td>5.19836</td>\n",
       "      <td>6820.87</td>\n",
       "      <td>0.999523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6.32950</td>\n",
       "      <td>5.74509</td>\n",
       "      <td>6.07319</td>\n",
       "      <td>6.32381</td>\n",
       "      <td>6.58806</td>\n",
       "      <td>6.91873</td>\n",
       "      <td>5868.06</td>\n",
       "      <td>0.999318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5.51917</td>\n",
       "      <td>4.96604</td>\n",
       "      <td>5.30488</td>\n",
       "      <td>5.53487</td>\n",
       "      <td>5.73794</td>\n",
       "      <td>6.03676</td>\n",
       "      <td>6503.72</td>\n",
       "      <td>0.999616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5.32798</td>\n",
       "      <td>4.74557</td>\n",
       "      <td>5.10920</td>\n",
       "      <td>5.34053</td>\n",
       "      <td>5.55930</td>\n",
       "      <td>5.86278</td>\n",
       "      <td>5863.53</td>\n",
       "      <td>0.999454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5.41919</td>\n",
       "      <td>4.88139</td>\n",
       "      <td>5.20760</td>\n",
       "      <td>5.42797</td>\n",
       "      <td>5.63613</td>\n",
       "      <td>5.92703</td>\n",
       "      <td>6586.55</td>\n",
       "      <td>0.999300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>5.81459</td>\n",
       "      <td>5.24067</td>\n",
       "      <td>5.60196</td>\n",
       "      <td>5.82447</td>\n",
       "      <td>6.03858</td>\n",
       "      <td>6.35249</td>\n",
       "      <td>6588.51</td>\n",
       "      <td>0.999481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>5.49187</td>\n",
       "      <td>4.94972</td>\n",
       "      <td>5.28068</td>\n",
       "      <td>5.50404</td>\n",
       "      <td>5.71932</td>\n",
       "      <td>5.99155</td>\n",
       "      <td>6201.50</td>\n",
       "      <td>1.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>5.37652</td>\n",
       "      <td>4.75456</td>\n",
       "      <td>5.13436</td>\n",
       "      <td>5.38209</td>\n",
       "      <td>5.61810</td>\n",
       "      <td>5.97439</td>\n",
       "      <td>4820.82</td>\n",
       "      <td>0.999193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>5.26962</td>\n",
       "      <td>4.74813</td>\n",
       "      <td>5.07028</td>\n",
       "      <td>5.28585</td>\n",
       "      <td>5.47101</td>\n",
       "      <td>5.75292</td>\n",
       "      <td>6155.08</td>\n",
       "      <td>0.999499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>5.94059</td>\n",
       "      <td>5.21942</td>\n",
       "      <td>5.66193</td>\n",
       "      <td>5.94380</td>\n",
       "      <td>6.22379</td>\n",
       "      <td>6.65844</td>\n",
       "      <td>6300.99</td>\n",
       "      <td>0.999987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>5.12461</td>\n",
       "      <td>4.54639</td>\n",
       "      <td>4.90466</td>\n",
       "      <td>5.13153</td>\n",
       "      <td>5.35153</td>\n",
       "      <td>5.66022</td>\n",
       "      <td>4693.75</td>\n",
       "      <td>1.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3.48505</td>\n",
       "      <td>2.66212</td>\n",
       "      <td>3.17502</td>\n",
       "      <td>3.49959</td>\n",
       "      <td>3.81259</td>\n",
       "      <td>4.22653</td>\n",
       "      <td>1711.46</td>\n",
       "      <td>1.000940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>5.32661</td>\n",
       "      <td>4.76951</td>\n",
       "      <td>5.09883</td>\n",
       "      <td>5.33654</td>\n",
       "      <td>5.55149</td>\n",
       "      <td>5.85721</td>\n",
       "      <td>5234.23</td>\n",
       "      <td>0.999745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>5.60480</td>\n",
       "      <td>5.05042</td>\n",
       "      <td>5.39061</td>\n",
       "      <td>5.61523</td>\n",
       "      <td>5.82932</td>\n",
       "      <td>6.14154</td>\n",
       "      <td>8045.46</td>\n",
       "      <td>0.999130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>5.66164</td>\n",
       "      <td>5.03820</td>\n",
       "      <td>5.41396</td>\n",
       "      <td>5.67216</td>\n",
       "      <td>5.90749</td>\n",
       "      <td>6.25642</td>\n",
       "      <td>6072.85</td>\n",
       "      <td>0.999513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>5.38963</td>\n",
       "      <td>4.86798</td>\n",
       "      <td>5.18260</td>\n",
       "      <td>5.39642</td>\n",
       "      <td>5.60313</td>\n",
       "      <td>5.88420</td>\n",
       "      <td>6970.07</td>\n",
       "      <td>0.999544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.42482</td>\n",
       "      <td>4.86610</td>\n",
       "      <td>5.19630</td>\n",
       "      <td>5.42993</td>\n",
       "      <td>5.65607</td>\n",
       "      <td>5.96769</td>\n",
       "      <td>7273.92</td>\n",
       "      <td>0.999291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>6.33845</td>\n",
       "      <td>5.69811</td>\n",
       "      <td>6.08582</td>\n",
       "      <td>6.34608</td>\n",
       "      <td>6.59519</td>\n",
       "      <td>6.95499</td>\n",
       "      <td>7061.51</td>\n",
       "      <td>0.999946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.20112</td>\n",
       "      <td>4.63514</td>\n",
       "      <td>4.98172</td>\n",
       "      <td>5.21455</td>\n",
       "      <td>5.42992</td>\n",
       "      <td>5.73544</td>\n",
       "      <td>7650.44</td>\n",
       "      <td>0.999450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>5.92269</td>\n",
       "      <td>5.35662</td>\n",
       "      <td>5.69086</td>\n",
       "      <td>5.93103</td>\n",
       "      <td>6.15826</td>\n",
       "      <td>6.46233</td>\n",
       "      <td>6256.39</td>\n",
       "      <td>0.999395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5.54091</td>\n",
       "      <td>4.98101</td>\n",
       "      <td>5.32418</td>\n",
       "      <td>5.54414</td>\n",
       "      <td>5.76775</td>\n",
       "      <td>6.07720</td>\n",
       "      <td>5935.96</td>\n",
       "      <td>0.999337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.74374</td>\n",
       "      <td>5.08834</td>\n",
       "      <td>5.49998</td>\n",
       "      <td>5.74908</td>\n",
       "      <td>6.00180</td>\n",
       "      <td>6.35363</td>\n",
       "      <td>5949.42</td>\n",
       "      <td>1.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>alpha_normalised</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>3.37914</td>\n",
       "      <td>2.52955</td>\n",
       "      <td>3.05082</td>\n",
       "      <td>3.39500</td>\n",
       "      <td>3.72095</td>\n",
       "      <td>4.16208</td>\n",
       "      <td>1041.88</td>\n",
       "      <td>1.004340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            variable  C   M     Mean       5%      25%      50%      75%  \\\n",
       "0   alpha_normalised  1   1  5.38631  4.81802  5.16575  5.39372  5.62138   \n",
       "1   alpha_normalised  1   2  5.03404  4.50915  4.82649  5.04351  5.24269   \n",
       "2   alpha_normalised  1   3  5.85896  5.25886  5.62377  5.87032  6.09556   \n",
       "3   alpha_normalised  1   4  6.22735  5.58510  5.96934  6.24014  6.49068   \n",
       "4   alpha_normalised  1   5  6.30527  5.67456  6.05886  6.30803  6.56363   \n",
       "5   alpha_normalised  1   6  5.13622  4.60722  4.92619  5.14621  5.35742   \n",
       "6   alpha_normalised  1   7  4.70524  4.13465  4.48862  4.71143  4.93371   \n",
       "7   alpha_normalised  1   8  5.92780  5.15570  5.61018  5.91999  6.24600   \n",
       "8   alpha_normalised  1   9  5.24260  4.71491  5.02770  5.25466  5.46240   \n",
       "9   alpha_normalised  1  10  5.45833  4.85158  5.21739  5.47406  5.70327   \n",
       "10  alpha_normalised  1  11  5.78892  5.17515  5.55274  5.79319  6.03913   \n",
       "11  alpha_normalised  1  12  4.92534  4.38732  4.71852  4.93312  5.14611   \n",
       "12  alpha_normalised  1  13  5.80717  5.23944  5.57942  5.81697  6.04676   \n",
       "13  alpha_normalised  1  14  4.73283  4.22334  4.53628  4.74700  4.93864   \n",
       "14  alpha_normalised  1  15  6.32950  5.74509  6.07319  6.32381  6.58806   \n",
       "15  alpha_normalised  1  16  5.51917  4.96604  5.30488  5.53487  5.73794   \n",
       "16  alpha_normalised  1  17  5.32798  4.74557  5.10920  5.34053  5.55930   \n",
       "17  alpha_normalised  1  18  5.41919  4.88139  5.20760  5.42797  5.63613   \n",
       "18  alpha_normalised  1  19  5.81459  5.24067  5.60196  5.82447  6.03858   \n",
       "19  alpha_normalised  1  20  5.49187  4.94972  5.28068  5.50404  5.71932   \n",
       "20  alpha_normalised  1  21  5.37652  4.75456  5.13436  5.38209  5.61810   \n",
       "21  alpha_normalised  1  22  5.26962  4.74813  5.07028  5.28585  5.47101   \n",
       "22  alpha_normalised  1  23  5.94059  5.21942  5.66193  5.94380  6.22379   \n",
       "23  alpha_normalised  1  24  5.12461  4.54639  4.90466  5.13153  5.35153   \n",
       "24  alpha_normalised  1  25  3.48505  2.66212  3.17502  3.49959  3.81259   \n",
       "25  alpha_normalised  1  26  5.32661  4.76951  5.09883  5.33654  5.55149   \n",
       "26  alpha_normalised  1  27  5.60480  5.05042  5.39061  5.61523  5.82932   \n",
       "27  alpha_normalised  1  28  5.66164  5.03820  5.41396  5.67216  5.90749   \n",
       "28  alpha_normalised  1  29  5.38963  4.86798  5.18260  5.39642  5.60313   \n",
       "29  alpha_normalised  1  30  5.42482  4.86610  5.19630  5.42993  5.65607   \n",
       "30  alpha_normalised  1  31  6.33845  5.69811  6.08582  6.34608  6.59519   \n",
       "31  alpha_normalised  1  32  5.20112  4.63514  4.98172  5.21455  5.42992   \n",
       "32  alpha_normalised  1  33  5.92269  5.35662  5.69086  5.93103  6.15826   \n",
       "33  alpha_normalised  1  34  5.54091  4.98101  5.32418  5.54414  5.76775   \n",
       "34  alpha_normalised  1  35  5.74374  5.08834  5.49998  5.74908  6.00180   \n",
       "35  alpha_normalised  1  36  3.37914  2.52955  3.05082  3.39500  3.72095   \n",
       "\n",
       "        95%    N_Eff     R_hat  \n",
       "0   5.92607  6719.16  0.999286  \n",
       "1   5.52481  6301.44  0.999518  \n",
       "2   6.44078  6193.23  0.999466  \n",
       "3   6.84753  6312.61  1.000360  \n",
       "4   6.90561  5330.25  0.999735  \n",
       "5   5.63415  6929.55  0.999514  \n",
       "6   5.24208  6227.78  0.999400  \n",
       "7   6.71451  4761.11  1.000260  \n",
       "8   5.73385  6326.87  0.999544  \n",
       "9   6.03089  5643.33  0.999882  \n",
       "10  6.38503  7027.98  0.999554  \n",
       "11  5.43436  5949.61  0.999587  \n",
       "12  6.34499  6359.12  0.999285  \n",
       "13  5.19836  6820.87  0.999523  \n",
       "14  6.91873  5868.06  0.999318  \n",
       "15  6.03676  6503.72  0.999616  \n",
       "16  5.86278  5863.53  0.999454  \n",
       "17  5.92703  6586.55  0.999300  \n",
       "18  6.35249  6588.51  0.999481  \n",
       "19  5.99155  6201.50  1.000050  \n",
       "20  5.97439  4820.82  0.999193  \n",
       "21  5.75292  6155.08  0.999499  \n",
       "22  6.65844  6300.99  0.999987  \n",
       "23  5.66022  4693.75  1.000300  \n",
       "24  4.22653  1711.46  1.000940  \n",
       "25  5.85721  5234.23  0.999745  \n",
       "26  6.14154  8045.46  0.999130  \n",
       "27  6.25642  6072.85  0.999513  \n",
       "28  5.88420  6970.07  0.999544  \n",
       "29  5.96769  7273.92  0.999291  \n",
       "30  6.95499  7061.51  0.999946  \n",
       "31  5.73544  7650.44  0.999450  \n",
       "32  6.46233  6256.39  0.999395  \n",
       "33  6.07720  5935.96  0.999337  \n",
       "34  6.35363  5949.42  1.000080  \n",
       "35  4.16208  1041.88  1.004340  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utilities import summary_to_tibble\n",
    "summary_to_tibble(fit, \"alpha_normalised\", \"C\", \"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_group</th>\n",
       "      <th>M</th>\n",
       "      <th>chain__</th>\n",
       "      <th>iter__</th>\n",
       "      <th>draw__</th>\n",
       "      <th>parameter</th>\n",
       "      <th>value</th>\n",
       "      <th>N_Eff</th>\n",
       "      <th>R_k_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>type[benign]</td>\n",
       "      <td>1.113950</td>\n",
       "      <td>4628.97</td>\n",
       "      <td>0.999658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285339</th>\n",
       "      <td>M6</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>2667</td>\n",
       "      <td>type[benign]</td>\n",
       "      <td>-1.184170</td>\n",
       "      <td>5277.88</td>\n",
       "      <td>1.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285338</th>\n",
       "      <td>M6</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>2667</td>\n",
       "      <td>type[benign]</td>\n",
       "      <td>-1.184170</td>\n",
       "      <td>5277.88</td>\n",
       "      <td>1.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285337</th>\n",
       "      <td>M6</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>2667</td>\n",
       "      <td>type[benign]</td>\n",
       "      <td>-1.184170</td>\n",
       "      <td>4202.42</td>\n",
       "      <td>1.001760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285336</th>\n",
       "      <td>M5</td>\n",
       "      <td>25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>2667</td>\n",
       "      <td>type[benign]</td>\n",
       "      <td>-0.383885</td>\n",
       "      <td>2011.00</td>\n",
       "      <td>1.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904000</th>\n",
       "      <td>CD8 4</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>1334</td>\n",
       "      <td>type[cancer] - type[benign]</td>\n",
       "      <td>-0.120878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904001</th>\n",
       "      <td>CD8 5</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>1334</td>\n",
       "      <td>type[cancer] - type[benign]</td>\n",
       "      <td>-0.316986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904002</th>\n",
       "      <td>CD8 6</td>\n",
       "      <td>15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>1334</td>\n",
       "      <td>type[cancer] - type[benign]</td>\n",
       "      <td>0.159390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903996</th>\n",
       "      <td>CD4 5</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>1334</td>\n",
       "      <td>type[cancer] - type[benign]</td>\n",
       "      <td>0.260115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>TM3</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>type[cancer] - type[benign]</td>\n",
       "      <td>-3.107210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cell_group   M  chain__  iter__  draw__                    parameter  \\\n",
       "0              B1   1      1.0     1.0       1                 type[benign]   \n",
       "285339         M6  26      3.0   667.0    2667                 type[benign]   \n",
       "285338         M6  26      3.0   667.0    2667                 type[benign]   \n",
       "285337         M6  26      3.0   667.0    2667                 type[benign]   \n",
       "285336         M5  25      3.0   667.0    2667                 type[benign]   \n",
       "...           ...  ..      ...     ...     ...                          ...   \n",
       "904000      CD8 4  13      2.0   334.0    1334  type[cancer] - type[benign]   \n",
       "904001      CD8 5  14      2.0   334.0    1334  type[cancer] - type[benign]   \n",
       "904002      CD8 6  15      2.0   334.0    1334  type[cancer] - type[benign]   \n",
       "903996      CD4 5   9      2.0   334.0    1334  type[cancer] - type[benign]   \n",
       "999999        TM3  36      4.0  1000.0    4000  type[cancer] - type[benign]   \n",
       "\n",
       "           value    N_Eff   R_k_hat  \n",
       "0       1.113950  4628.97  0.999658  \n",
       "285339 -1.184170  5277.88  1.000790  \n",
       "285338 -1.184170  5277.88  1.000790  \n",
       "285337 -1.184170  4202.42  1.001760  \n",
       "285336 -0.383885  2011.00  1.001210  \n",
       "...          ...      ...       ...  \n",
       "904000 -0.120878      NaN       NaN  \n",
       "904001 -0.316986      NaN       NaN  \n",
       "904002  0.159390      NaN       NaN  \n",
       "903996  0.260115      NaN       NaN  \n",
       "999999 -3.107210      NaN       NaN  \n",
       "\n",
       "[1000000 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utilities import get_abundance_contrast_draws\n",
    "get_abundance_contrast_draws(data, contrasts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
